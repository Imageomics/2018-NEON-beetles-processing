# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.16.4
#   kernelspec:
#     display_name: std
#     language: python
#     name: python3
# ---

# %%
import pandas as pd
import seaborn as sns

# %% [markdown]
# # Beetlepalooza Beetle Measurement Data
#
# This dataset has images of multiple beetles from each site (the individual beetles will be segmented out). Each image has multiple rows in the measurements CSV (2 per beetle annotation, one representing each of the two measurements performed on the beetles; there are multiple annotations per beetle, so it's more than 2 per).
#
# We need to explore the variation in annotations. In `EDA-0-1` we discovered at least one instance of the length and width measurements of the elytra being transposed (since this generated a very obvious outlier). That analysis just looked at the first measurement available in each category for each individual. We want to compare all measurements for each individual to decide how they vary and which to use (or if we should take an average of the provided annotations, etc.).
#
# This will also be important in deciding how to do the individual segmentation so that we can get images with just one beetle per image (suggestion was to use the provided coordinates to get an approximate bounding box and use SAM).

# %%
df = pd.read_csv("https://huggingface.co/datasets/imageomics/BeetlePalooza/resolve/15a82c862588b2e7b709b1aa982161d8c3a7c75f/BeetleMeasurements.csv", low_memory = False)
df.head()

# %% [markdown]
# Column info:
#   - `pictureID`: Name of the image: `<sample-barcode>.jpg`. Unique identifier for _group_ images, not for dataset. --- Probably should lowercase this.
#   - `scalebar`: Pixel coordinates of the ruler/scalebar in the image.
#   - `scm_pix`: Integer. The length in pixels of one cm on the scalebar.
#   - `individual`: Integer. The beetle in the image to whom the measurements refer. Awaiting confirmation of how they are counted.
#   - `structure`: Whether the measurement applies to the length or width of the elytra (`ElytraLength` or `ElytraWidth`, respectively).
#   - `lying_straight`: Whether or not the beetle is "straight" in the image (`Yes` or `No`). Further guidance on this term's meaning would be helpful.
#   - `coords_pix`: Pixel coordinates of the line marking the length or width of the elytra (green or purple --confirm which is which). Note that the lines are more than one pixel wide, which is why these coordinates form a rectangle.
#   - `dist_pix`: Float. The length or width of the elytra (indicated by `structure`) as measured in pixels.
#   - `dist_cm`: Float. The length or width of the elytra (indicated by `structure`) as measured in centimeters using the scalebar (the red line in the reference image denotes the pixel count for 1cm).
#   - `scientificName`: Scientific name of the specimen (`<Genus> <species>`).
#   - `NEON_sampleID	`: NEON identifier for the sample (576 unique IDs), prefixed by the `plotID`.
#   - `siteID`: String. Identifier for the site from which the specimens were collected.
#   - `site_name`: Name of field site from which the specimens were collected.
#   - `plotID`: Identifier for the plot from which the specimens were collected (`<siteID>_<plot number>`).
#   - `user_name`: Name of person inputting the information? (`<first><Last>`) or just their username in the system?
#   - `workflowID`: Integer identifier for the workflow used...??
#   - `genus`: Genus of the individual (generated by taking the first word in the `scientificName`).
#   - `species`: Species of the individual (generated from the word(s) following the `genus` in the `scientificName`). There are 78 unique species labeled.
#   - `individualID`: Unique identifier for the beetles (based on the assumed uniqueness of the `PictureID`), generated from `PictureID` (minus the `.jpg`) plus `_<individual>`.
#   - `file_name`: Relative path to image from the root of the directory (`<group_images>/<pictureID>.jpg`); allows for image to be displayed in the dataset viewer alongside its associated metadata.

# %%
df.info()

# %%
df.nunique()

# %% [markdown]
# ## Exploring Multiple Annotations
#
# We saw in `EDA-0-1` that there isn't any full duplication (as in, rows are not repeated), but clearly the same individuals have been annotated multiple times. We need to understand how much matches vs degree of variation with the others.
#
# Let's check for duplication between `individualID` and `structure` to get a picture of how many elytra (length & width) measurements there are for each individual (do we have at least 2 for each?).

# %%
df["duplicate_annotation"] = df.duplicated(subset = ["individualID", "structure"], keep = "first")
df["duplicate_annotation"].value_counts()

# %% [markdown]
# Considering we have 11,104 individuals, each of whom would get two measurements, we have at _most_ 8,428 individuals annotated twice (though we know there's at least one instance of an individual annotated three times).

# %%
for username in list(df.user_name.unique()):
    temp = df.loc[df["user_name"] == username].copy()
    print(f"{username} annotated {temp.pictureID.nunique()} images in {temp.shape[0]} entries, with {temp.individualID.nunique()} unique individuals (picID + individual)")

# %% [markdown]
# ### Add number of annotations per individual
#
# Let's add a column indicating the number of annotations per individual; we'll count each measurement (length _and_ width) in case there are any discrepancies (though that seems unlikely).

# %%
individuals_gp = df.groupby("individualID")

for individual, group in individuals_gp:
    df.loc[df["individualID"] == individual, "num_measurements"] = len(group)
    
df["num_measurements"].value_counts()

# %% [markdown]
# This suggests we have 7,010 individuals that are only annotated once, 77 annotated twice, 3,976 annotated 3 times, ..., 34 annotated 11 times, and one that somehow was annotated 27 times!
#
# Let's separate out the edge cases 

# %%
df.loc[df["num_measurements"] == 54.0].nunique()

# %% [markdown]
# At least all the variation is coming from the coordinates. Though, there is disagreement over whether or not the beetle is straight. I believe we should have consistency between `pictureID` and `NEON_sampleID`, as I would expect for `siteID` & `site_name`, but let's start by just checking that the following are consistent for each individual.
#
# | column | unique values |
# | ---- | --- |
# | pictureID            | 577 |
# | scientificName       | 85 |
# | NEON_sampleID        | 576 |
# | siteID               | 30 |
# | site_name            | 43 |
# | plotID               | 144 |
#
#
# Would also expect to have the same number of distinct `dist_pix` and `dist_cm` since the latter is meant to be derived from the former, presumably by the same algorithm, but it seems the `cm_pix` varies...

# %%
id_info_cols = ["individualID", "pictureID", "scientificName", "NEON_sampleID", "siteID", "site_name", "plotID"]
df["duplicated_id_info"] = df.duplicated(subset = id_info_cols, keep = False)
df["duplicated_id_info"].value_counts()

# %%
# Check with keep in case of, e.g., 2 & 2 duplication
df["dupe_id_info"] = df.duplicated(subset = id_info_cols, keep = "first")
df["dupe_id_info"].value_counts()

# %% [markdown]
# That looks promising, we'll double check that's all unique individualIDs, then check for pure duplication on measurements for individuals. We also need to check on scale bar consistency (at least for the length and width measurements that get matched).

# %%
df.loc[~df["dupe_id_info"], "individualID"].nunique()

# %% [markdown]
# Okay, good. These are indeed all consistent across individuals.
#

# %%
measurement_columns = ["pictureID", "individualID", "cm_pix", "lying_straight", "structure", "dist_pix", "dist_cm"]
df["dupe_meas"] = df.duplicated(subset = measurement_columns, keep = "first")
df["dupe_meas"].value_counts()

# %% [markdown]
# Ah, we have 55 potentially duplicated records. We checked previously for full duplication, so let's set `keep = False` and see where they differ.

# %%
df["dupe_record"] = df.duplicated(subset = measurement_columns, keep = False)
dupe_meas_df = df.loc[df["dupe_record"]].copy()
print(dupe_meas_df.shape)
dupe_meas_df.nunique()

# %%
# what is the unique coords_pix?
temp = dupe_meas_df.copy()
temp["dupe_coords"] = temp.duplicated(subset = ["coords_pix"], keep = False)
temp.loc[temp["dupe_coords"]]

# %% [markdown]
# Interesting. Most of the variation is coming from the coordinates of the elytra measurement lines. The `scalebar` coordinates are also inconsistent within the same pictures, but that may be due to annotator. We have 107 entries representing 38 individuals (which should have 76 unique entries between them, so this is likely still a subset of their total number of records).

# %%
dupe_meas_df.user_name.value_counts()

# %%
potential_duplicate_meas = [col for col in list(dupe_meas_df.columns)[:-6] if col not in ["coords_pix", "user_name", "workflowID"]]
dupe_meas_df["practical_meas_dupes"] = df.duplicated(subset = potential_duplicate_meas, keep = False)
dupe_meas_df["practical_meas_dupes"].value_counts()

# %%
print(f"We have {dupe_meas_df.loc[dupe_meas_df['practical_meas_dupes'], 'individualID'].nunique()} individuals with true duplication (other than coordinates of the lines)")
print(f"We have {dupe_meas_df.loc[~dupe_meas_df['practical_meas_dupes'], 'individualID'].nunique()} individuals that don't have duplication in measurements (even beyond pixel lines)")

# %% [markdown]
# We clearly have a few individuals in both groups...

# %%
print(dupe_meas_df.loc[dupe_meas_df['practical_meas_dupes'], 'structure'].value_counts())
print(dupe_meas_df.loc[~dupe_meas_df['practical_meas_dupes'], 'structure'].value_counts())

# %% [markdown]
# duplication is not balanced between structures either.

# %%
print(f"We have {dupe_meas_df.loc[dupe_meas_df['practical_meas_dupes'], 'pictureID'].nunique()} photos with true duplication (other than coordinates of the lines)")
print(f"We have {dupe_meas_df.loc[~dupe_meas_df['practical_meas_dupes'], 'pictureID'].nunique()} photos that don't have duplication in measurements (even beyond pixel lines)")

# %% [markdown]
# Similarly for the group photos. 

# %%
dupe_meas_df.loc[dupe_meas_df["user_name"] == "ishachinniah", "practical_meas_dupes"].value_counts()

# %% [markdown]
# Okay, so the practical duplicates (measures that are consistent in all but coordinate location of the lines) are all from one user.

# %%
dupe_meas_df["practical_meas_dupes_kept"] = df.duplicated(subset = potential_duplicate_meas, keep = "first")
dupe_meas_df["practical_meas_dupes_kept"].value_counts()

# %% [markdown]
# ## Rough Comparison of Measurements

# %%
df_meas = pd.DataFrame({"elytraLength_pix": list(df.loc[df["structure"] == "ElytraLength", "dist_pix"]),
                        "elytraWidth_pix": list(df.loc[df["structure"] == "ElytraWidth", "dist_pix"]),
                        "elytraLength_cm": list(df.loc[df["structure"] == "ElytraLength", "dist_cm"]),
                        "elytraWidth_cm": list(df.loc[df["structure"] == "ElytraWidth", "dist_cm"]),
                        "user_name": list(df.loc[df["structure"] == "ElytraWidth", "user_name"]),
                        "genus": list(df.loc[df["structure"] == "ElytraWidth", "genus"]),
                        "species": list(df.loc[df["structure"] == "ElytraWidth", "species"]),
                        "individualID": list(df.loc[df["structure"] == "ElytraWidth", "individualID"])}) # should match up
df_meas.head()

# %% [markdown]
# Plot pixel measurements colored by `user_name`.

# %%
sns.scatterplot(df_meas, x = "elytraLength_pix", y = "elytraWidth_pix", hue = "user_name")

# %%
# color by genus

sns.scatterplot(df_meas, x = "elytraLength_pix", y = "elytraWidth_pix", hue = "genus", legend = False)

# %% [markdown]
# Plot cm measurements colored by `user_name`.

# %%
sns.scatterplot(df_meas, x = "elytraLength_cm", y = "elytraWidth_cm", hue = "user_name")

# %%
# color by genus

sns.scatterplot(df_meas, x = "elytraLength_cm", y = "elytraWidth_cm", hue = "genus", legend = False)

# %%
# color by species

sns.scatterplot(df_meas, x = "elytraLength_cm", y = "elytraWidth_cm", hue = "species", legend = False)

# %%

# %% [markdown]
# We would expect length to always be more than the width of the elytra based on where the measurements are made, so we can filter outliers based on a comparison of length to width.
#
# ![annotation image](beetles.png)
#
# green and purple lines indicate the measurement used for the elytra length and width, respectively. The red line marks the pixels for 1cm.

# %%
df_meas["outliers"] = df_meas["elytraLength_pix"] < df_meas["elytraWidth_pix"]
df_meas.loc[df_meas["outliers"]]

# %% [markdown]
# Isadora says the first one looks damaged, may lead to inconsistency. Looking at picture, the first one (`A00000046078_10`) is missing half the elytra (length-wise cut). `A00000046104_10` is just at an angle, length is definitely more than the width. We'll only be using Isadora's annotations anyway, so we'll just fix the first one (switch length and width) and not worry about the second.

# %%
df.loc[df["individualID"].isin(["A00000046078_10", "A00000046104_10"])]

# %% [markdown]
# Let's check on those other couple outliers...

# %%
df_meas.loc[(df_meas["elytraLength_cm"] > .7) & (df_meas["elytraWidth_cm"] < .2)]

# %% [markdown]
# This seems like a conversion error, also isn't part of annotations we'll be using.

# %%
df_meas.loc[(df_meas["elytraLength_cm"] > 1.7) & (df_meas["elytraWidth_cm"] < 1)]

# %%
df.loc[df["individualID"] == "A00000046075_1"]

# %% [markdown]
# These all seem pretty consistent, most likely natural fluctuation.

# %% [markdown]
# ### Save initial Measurement DataFrame with all Annotators for record

# %%
df_meas.to_csv("../metadata/all_measurements.csv", index = False)

# %% [markdown]
# ## IsaFluck: Zooniverse limits to 99 individuals per image then resets count 
#
# Ex: `A00000051542.jpg` has 122 individuals.
#
# Also note, the inconsistency between unique images and `NEON_sampleID` is due to (`RMNP_014.20180709.CALADV.01`); there were too many individuals in the sample for Isadora to organize them all in one picture. She placed them in two pictures: `A00000051555_1` and `A00000051555_2`.
#
#
# To try to address the too many individuals for Zooniverse issue, we'll add a count of number of measurements per image. Note, we still know there are some duplicate measurements, so let's just get the number of lines per image and the largest `individual` number.
#

# %%
meas_gp = df.groupby("pictureID")

for picID, group in meas_gp:
    if len(group)%2 != 0:
        print(f"picture {picID} has an uneven number of measurements recorded")
    df.loc[df["pictureID"] == picID, "num_pic_meas"] = len(group)
    df.loc[df["pictureID"] == picID, "max_individual"] = max(list(df.loc[df["pictureID"] == picID, "individual"].unique()))
    
print(df["num_pic_meas"].value_counts())
print("most meas: ", max(list(df["num_pic_meas"])), "least: ", min((list(df["num_pic_meas"]))))
print()
print("largest individual number recorded:")
print(df["max_individual"].value_counts())
print(f"least number of individuals in a single image: {min(list(df['max_individual']))}")

# %% [markdown]
# Least number of measurements does correspond to the least number of individuals in an image. The challenge will be with the larger ones. We need to see how many unique measurements there are looking at just each annotator.
#
# The best way to get a comparison would probably be to separate out the images where `max_individual < 99.0`, as we see below, the highest annotation count is for 214 annotations from each annotator (it seems maybe only a few had triple annotation, so we'll check on that then start splitting for comparison).

# %%
df.loc[df["num_pic_meas"] == 642.0].sample(2)

# %%
df.loc[df["num_pic_meas"] == 642.0, "user_name"].value_counts()

# %%
# check that one coords_pix dupe, since the only individual showing up is # 7:

df.loc[df["pictureID"] == "A00000033675.jpg", "max_individual"].values[0]

# %% [markdown]
# Yes, this one does have an actual measure duplication. Let's check who annotated that individual to see if it's two annotators or just one.

# %%
dupe_ID = df.loc[df["individualID"] == "A00000033675_7"]
dupe_ID[["scalebar", "cm_pix", "individual", "structure", "lying_straight", "coords_pix", "dist_pix", "dist_cm", "user_name"]]

# %% [markdown]
# Okay, the `coords_pix` duplication is two annotators marking the same line. Seems 2 out of 3 matched on the width of the elytra.

# %% [markdown]
# ### Compare Images with Multiple Annotators

# %%
multi_annotator = {}
double_annotator = []

for picID, group in meas_gp:
    num_annotators = df.loc[df["pictureID"] == picID, "user_name"].nunique()
    df.loc[df["pictureID"] == picID, "num_annotators"] = num_annotators
    if num_annotators > 1:
        multi_annotator[picID] = (df.loc[df["pictureID"] == picID, "max_individual"].values[0], df.loc[df["pictureID"] == picID, "num_pic_meas"].values[0])
        if num_annotators == 2:
            double_annotator.append(picID)

print(len(multi_annotator.keys()))
print(len(double_annotator))

# %%
double_annotator

# %%
multi_annotator[double_annotator[0]]

# %%
ma_df = pd.DataFrame(data = {"pictureID": multi_annotator.keys(),
                             "max_individual": [multi_annotator[picID][0] for picID in multi_annotator.keys()],
                             "num_annotators": [3 if picID != double_annotator[0] else 2 for picID in multi_annotator.keys()],
                             "num_pic_meas": [multi_annotator[picID][1] for picID in multi_annotator.keys()]})

ma_df.head()

# %%
ma_df["expected_num_meas"] = ma_df["num_pic_meas"]/ma_df["num_annotators"]
ma_df.nunique()

# %%
print(max(list(ma_df["expected_num_meas"])), min(list(ma_df["expected_num_meas"])))

# %% [markdown]
# So this should contain images with as few as 1 and as many as 107 individuals.

# %% [markdown]
# ### Save this df for record

# %%
ma_df.to_csv("../metadata/multi_annotator_count.csv", index = False)
